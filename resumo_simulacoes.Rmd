---
title: "Resumo das simulações usando o hipercubo"
author: "Paulo Inácio Prado"
date: "`r format(Sys.time(), '%d de %B de %Y')`"
output: 
        rmdformats::readthedown:
        self_contained: true
        thumbnails: true
        lightbox: true
        gallery: false
        highlight: tango
        toc_depth: 4
---

```{r setup, echo=FALSE, warning=FALSE, message=F}
library(knitr); 
library(ggplot2)
library(dplyr); library(tidyr);
library(xtable)

opts_chunk$set(fig.align = 'center', fig.show = 'hold', fig.height = 5, fig.width = 5,
               warning = FALSE, message = FALSE, error = FALSE, echo=FALSE)
options(formatR.arrow = TRUE,width = 90, cache=TRUE)
source("functions.R")
load("abacus/tresults.RData")
load("abacus/corresults.RData")
load("abacus/anovaresults.RData")
load("abacus/lmresults.RData")
```

# Resumo das simulações

## Situações simuladas
  * teste t, 
  * correlação simples
  * anova de um fator de 3 níveis. Apenas grupo tem diferença com os outros dois, 
  * regressão linear com duas  preditoras, sendo que apenas uma afeta a resposta:
    * preditoras não correlacionadas
    * preditoras têm correlação de 0,5 (colinearidade)

## Parâmetros da simulação

##### Tamanho do efeito. 
É uma função do tamanho da amostra, do valor da estatística (diferença entre médias, coeficientes ou correlações), e o desvio-padrão da variável resposta. Em todos os casos o efeito cresce se a amostra é grande, se a diferença é grande e se o desvio-padrão das diferenças é pequeno. Em todos os casos o tamanho do efeito pdoe ser interpretado como uam generalização da estatística t. As expressões para tamanho do efeito para situação são:

   * teste t: o próprio valor de t para amostras de mesmo tamanho e mesma variância: (x1 - x2) / (sd / sqrt(2/n))
   * correlação: coeficiente de correlação convertido para estatística t: r * sqrt((n-2) / (1-r^2) )
   * anova: diferença do grupos em relação aos outros, expresso na escala de t: (x1 - x2) / (sd / sqrt(3/n))
   * coeficiente angular a regressão: conversão para a escala de t: beta / (sd / sqrt(n))

##### Tamanho da amostra
 * teste t e anova: n de observações em cada tratamento
 * correlação e regressões: n de observações
 
##### Desvio-padrão da resposta
Em todos os casos todas as populações amostradas tinha um mesmo desvio-padrão (homocedasticidade).

 * teste t: desvio-padrão das distribuições gaussianas dos valores nas duas populações amostradas
 * anova: idem para as três populações amostradas
 * correlação: desvio-padrão das distribuições marginais da gaussiana bivariada da qual são tomadas as amostras
 * regressão linear: desvio-padrão do coeficiente angular
 
### Amostragem dos parâmetros

Duas mil combinações dos parâmetros foram sorteadas com o método do hipercubo latino.
No sorteio todos os valores tinham a mesma probabilidade (distribuição uniforme), dentro
dos seguintes intervalos:

* Tamanho do efeito: 0,1 a 8,0
* Tamanho amostral: 10 a 100
* Desvio-padrão da resposta: 0,1 a 8

Os demais valores estão descritos no manuscrito, e foram mantidos constantes.

## Output das simulações

Para cada combinação de parâmetros foram realizadas dez mil simulações.
Os resultados estão nos arquivos RData relacionados no final desse arquivo.
Em cada um desses arquivos há dataframes com oito valores calculados para
cada bateria com uma combinação de parâmetros:

* *p.NHT.right* : Proporção de conclusões corretas por NHT
* *p.AIC.right* :Proporção de conclusões corretas por IT, critério 1 (ver a seguir)
* *p.AIC.right.2* :Proporção de conclusões corretas por IT, critério 2 (ver a seguir)
* *p.mismatch* : Proporção de discordâncias entre NHT e IT, critério 1
* *p.mismatch.2* : Proporção de discordâncias entre NHT e IT, critério 2
* *mean.NHT.M* : Média do erro tipo M (Gelman & Carlin 2014) para NHT
* *mean.AIC.M* : Média do erro tipo M para IT 1
* *mean.AIC.M.2* : Média do erro tipo M para IT 2
* *p.NHT.S* : proporção de erro tipo S (Gelman & Carlin 2014) para NHT
* *p.AIC.S* : proporção de erro tipo S para IT 1
* *p.AIC.S.2* : proporção de erro tipo S para IT 2
* *mean.pvalue* : média do valor p para H0, por NHT
* *mean.wH0* : média do peso de Akaike para H0, por IT

### Critérios para associar IT a uma conclusão correta

Tínhamos definido que o IT chegou a uma conclusão correta
se o modelo correpondente tivesse Delta-AIC = 0. Chamamos isso de **critério 1**.
Na reunião de 03/10/17 chegamos à conclusão que um critério mais adequado seria 
que uma conclusão é correta apenas se o modelo correspondente tivesse
o menor AIC (dAIC = 0) e todos os demais tivessem delta-AIC > 2. 
Chamei esse de **critério 2**. 

Nas simulações em que havia mais de dois modelos concorrentes (anova e
regressão) a proporção de conclusões corretas de IC chegava a uma
assíntota de 86%. Isso acontece pq há uma probabilidade de no mínimo
16% de que modelos com um parâmetro a mais mas não informativo
(coeficiente próximo de zero mas suficiente para dar um melhor ajuste)
sejam selecionados. Isso é apontado no artigo do Arnold [^1], que sugere
então que se aplique um critério adicional de parcimônia neste caso. O
critério seria de escolher entre os modelos empatados o com menor
número de parâmetros. A partir do Arnold cheguei a artigos
estatísticos que provam que a probabilidade de inclusão de uma
parâmetro não informativo em modelos lineares Gaussianos é mesmo cerca
de 16% [^2]. Então é um procedimento bem fundamentado, apesar de
inicialmente eu considerar heterodoxo demais para colocarmos neste
artigo. Graças à indicação inicial do Leo do artigo do Arnold é que me
caiu a ficha.

Assim, incluí no critério dois a solução proposta por
Arnold, simulando a situação em que o usuário chegaria à
conclusão correta se escolhesse o modelo mais simples entre os
empatados. Para teste t e correlação, em que há apenas dois modelos
concorrentes, isso equivale a considerar válido todas as seleções com
delta-AIC do modelo correto <2. Para anova e regressão
ficou assim:

* Quando havia a presença do efeito (diferença de um
  grupo na anova ou efeito de uma preditora na regressão), considerei
  corretas as seleções em que apenas modelos com este efeito estavam
  selecionados, mesmo que entre eles houvesse modelos com efeitos
  adicionais também selecionados. No caso da ANOVA, isso acontece
  quando o modelo de diferença entre todos os grupos empata com o
  modelo de diferença apenas do grupo correto. No caso da regressão,
  isso acontece quando o modelo com a preditora correta empata com o
  modelo com o modelo com as duas preditoras. Note que nos dois casos
  se apenas o modelo com parâmetros adicionais for selecionado a
  conclusão foi considerada incorreta.
* Nos casos de ausência de efeito (H0 correta), considerei corretas
  também as seleções em que os modelos empatados formavam uma
  hieraquia (nested), incluindo o nulo. Nestes casos o usuário também
  chega ao modelo nulo se optar pelo modelo mais simples, o que pode
  acontecer de várias maneiras:
   * y~1 e y~x1
   * y~1 e y~x1 e y ~ x1+x2
   * y~1 e y~x2
   * y~1 e y~x2 e y~x1+x2
   
  

# Resultados para quando há efeito (H0 falsa)

Abaixo vão os gráficos comparando NHT com os dois critérios,
para os casos em que a há efeitos (H0 falsa). Este gráficos portanto
mostram o poder de cada procedimento. 


## Probability of rightfull conclusions

```{r prob rightful conclusions}
p1b(t.results, main = "t-test", cex=0.25)
p1b(cor.results, main = "Correlation" , cex=0.25)
p1b(anova.results, main = "Anova", cex=0.25)
p1b(lm.results, main = "Linear regression, no collinearity", cex=0.25)
p1b(lm.colin.results, main = "Linear regression, with collinearity", cex=0.25)
```


## Probability of conclusion mismatch

```{r prob mismatch}
p2b(t.results, pos.leg = "topright", main = "t-test")
p2b(cor.results,  pos.leg = "topright", main = "Correlation")
p2b(anova.results,  pos.leg = "topright", main = "Anova")
p2b(lm.results,  pos.leg = "topright", main = "Linear regression, no collinearity")
p2b(lm.colin.results,  pos.leg = "topright", main = "Linear regression, with collinearity")
``` 

## Mean M-error

```{r mean M-error}
p3b(t.results,  pos.leg = "topright", main = "t-test", cex=0.25)
p3b(cor.results, pos.leg = "topright", main = "Correlation", cex=0.25)
p3b(anova.results, pos.leg = "topright", main = "Anova", cex=0.25)
p3b(lm.results, pos.leg = "topright", main = "Linear regression, no collinearity", cex=0.25)
p3b(lm.colin.results, pos.leg = "topright", main = "Linear regression, with collinearity", cex=0.25)
```

## Proportion of S-error

```{r prob s-error}
p4b(t.results, pos.leg = "topright", main = "t-test", cex=0.25)
p4b(cor.results, pos.leg = "topright", main = "Correlation", cex=0.25)
p4b(anova.results, pos.leg = "topright", main = "Anova", cex=0.25)
p4b(lm.results, pos.leg = "topright", main = "Linear regression, no collinearity", cex=0.25)
p4b(lm.colin.results, pos.leg = "topright", main = "Linear regression, with collinearity", cex=0.25)
```

# Resultados para H0 verdadeira

Nas simulações para H0 verdadeira não há variação do efeito, então fiz
gráficos da probabilidade de conclusões corretas em função do erro
padrão (desvio-padrão / raiz quadrada do tamanho da amostra).
Ainda assim, acho que estes gráficos podem ir para o material
suplementar, porque não há muita variação importante. Aí poderíamos colocar 
no texto principal apenas uma tabela com a proporção de erro tipo I em cada
tipo de análise.

## Graficos

```{r type-I error}
p1b(t.results0, H0=TRUE, cex=0.25, main="t-test")
p1b(cor.results0, H0=TRUE, cex=0.25, main="Correlation")
p1b(anova.results0, H0=TRUE, cex=0.25, main="ANOVA")
p1b(lm.results0, H0=TRUE, cex=0.25, main="Regression")
p1b(lm.colin.results0, H0=TRUE, cex=0.25, main="Regression, collinearity")
```

## Probabilidade média de erro tipo I

A tabela, igual à que coloquei no artigo, tem a proporção
de todas as simulações em que H0 era verdadeira e cada abordagem
chegou á conclusão correta:

```{r type-I error tbale}
tab.errorI <- data.frame(
    row.names=c("NHT", "IT crit. 1", "IT crit. 2"),
    T.test = apply(t.results0[, 3:5],2,mean),
    Correla = apply(cor.results0[, 3:5],2,mean),
    Anova = apply(anova.results0[, 3:5],2,mean),
    Regr = apply(lm.results0[, 3:5],2,mean),
    Regr.colin = apply(lm.colin.results0[, 3:5],2,mean)
)
kable(t(tab.errorI), digits=3)
#print(xtable(t(tab.errorI[c(1,3),]), digits=3), booktabs=TRUE)

```

# p-value x Akaike weight

### Na região de interesse:

```{r p x w}
plot(mean.pvalue ~ mean.wH0, data= t.results,
         xlab = "Akaike weight for H0",
     ylab = "p for H0", subset=mean.pvalue <0.1, cex=0.4,
     xlim = c(0,
              max(sapply(list(t.results, cor.results, anova.results, lm.results, lm.colin.results),
                         function(x) max(x$mean.wH0[x$mean.pvalue <0.1]))))
     )
points(mean.pvalue ~ mean.wH0, data= cor.results,
       subset=mean.pvalue <0.1, cex=0.4, col = "red")
points(mean.pvalue ~ mean.wH0, data= anova.results,
       subset=mean.pvalue <0.1, cex=0.4, col = "blue")
points(mean.pvalue ~ mean.wH0, data= lm.results,
       subset=mean.pvalue <0.1, cex=0.4, col = "orange")
legend("bottomright", c("t-test", "Correlation", "ANOVA", "Linear regression"),
       col = c("black", "red", "blue", "orange"), pch=19, bty="n")
```

### Ao longo de todo intervalo de p

```{r p x w todo p}
plot(mean.pvalue ~ mean.wH0, data= t.results,
         xlab = "Akaike weight for H0",
     ylab = "p for H0",  cex=0.4)
points(mean.pvalue ~ mean.wH0, data= cor.results,
        cex=0.4, col = "red")
points(mean.pvalue ~ mean.wH0, data= anova.results,
        cex=0.4, col = "blue")
points(mean.pvalue ~ mean.wH0, data= lm.results,
        cex=0.4, col = "orange")
legend("topleft", c("t-test", "Correlation", "ANOVA", "Linear regression"),
       col = c("black", "red", "blue", "orange"), pch=19, bty="n")
```

# Próximos passos

* Reescrever a metodologia para explicar o hipercubo e erros tipo M e S, e também o critério de parcimônia do Arnold.
* Atualizar os resultados (rever os padrões, incluir descrição dos erros M e S)
* Rever material suplementar
* Rever discussão (não deve precisar mudar muita coisa)

# Arquivos

## Códigos em R

* Comandos que rodaram a simulação no cluster (bem demorado, apenas para documentar): [simulations_rightful_conclusions.R](simulations_rightful_conclusions.R)
* Funções para realizar as simulações e gráficos. A funções das simulações têm comentários em formato Roxygen que podem gerar uma página de ajuda. Lá há mais detalhes sobre as simulações: [functions.R](functions.R)
* O arquivo base deste página, que tem os comandos usados para gerar os gráficos: [resumo_simulacoes.Rmd](resumo_simulacoes.Rmd)

## Resultados das simulações

Basta carregar os binários abaixo em sua área de trabalho e vc terá os dataframes com os resultados
das simulações, como descritos na seção **Output das simulações**:

* [tresults.RData](abacus/tresults.RData)
* [corresults.RData](abacus/corresults.RData)
* [anovaresults.RData](abacus/anovaresults.RData)
* [lmresults.RData](abacus/lmresults.RData)

[^1]: Arnold, T.W. Uninformative parameters and model selection using Akaike's Information Criterion. Journal of Wildlife Management, 2010, 74.6: 1175-1178.

[^2]: Teräsvirta, T., & Mellin, I. (1986). Model selection criteria and model selection tests in regression models. Scandinavian Journal of Statistics, 159-171; Geweke, J., & Meese, R. (1981). Estimating regression models of finite but unknown order. International Economic Review, 55-70. Veja também Aho, K., Derryberry, D., & Peterson, T. (2014). Model selection for ecologists: the worldviews of AIC and BIC. Ecology, 95(3), 631-636, para uma interpretação de que isso é o preço que o AIC paga por minimizar perda de informação.
